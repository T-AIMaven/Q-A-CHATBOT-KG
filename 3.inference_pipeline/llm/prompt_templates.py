from abc import ABC, abstractmethod

from langchain.prompts import PromptTemplate
from pydantic import BaseModel


class BasePromptTemplate(ABC, BaseModel):
    @abstractmethod
    def create_template(self, *args) -> PromptTemplate:
        pass


class QueryExpansionTemplate(BasePromptTemplate):
    prompt: str = """You are an AI language model assistant. Your task is to generate {to_expand_to_n}
    different versions of the given user prompt to retrieve relevant documents from a vector
    database. By generating multiple perspectives on the user question, your goal is to help
    the user overcome some of the limitations of the distance-based similarity search.
    Provide these alternative questions seperated by '{separator}'.
    Original question: {question}"""

    @property
    def separator(self) -> str:
        return "#next-question#"

    def create_template(self, to_expand_to_n: int) -> PromptTemplate:
        return PromptTemplate(
            template=self.prompt,
            input_variables=["question"],
            partial_variables={
                "separator": self.separator,
                "to_expand_to_n": to_expand_to_n,
            },
        )


class SelfQueryTemplate(BasePromptTemplate):
    prompt: str = """You are an AI language model assistant. Your task is to extract information from a user prompt.
    The required information that needs to be extracted is the special or particular event. 
    Your response should consists of only the extracted event to help generate the video, nothing else.
    User question: {question}"""

    def create_template(self) -> PromptTemplate:
        return PromptTemplate(template=self.prompt, input_variables=["question"])


class RerankingTemplate(BasePromptTemplate):
    prompt: str = """You are an AI language model assistant. Your task is to rerank passages related to a query
    based on their relevance. 
    The most relevant passages should be put at the beginning. 
    You should only pick at max {keep_top_k} passages.
    The provided and reranked documents are separated by '{separator}'.
    
    The following are passages related to this query: {question}.
    
    Passages: 
    {passages}
    """

    def create_template(self, keep_top_k: int) -> PromptTemplate:
        return PromptTemplate(
            template=self.prompt,
            input_variables=["question", "passages"],
            partial_variables={"keep_top_k": keep_top_k, "separator": self.separator},
        )

    @property
    def separator(self) -> str:
        return "\n#next-document#\n"


class InferenceTemplate(BasePromptTemplate):
    simple_prompt: str = """You are an AI language model assistant. Your task is to generate a cohesive and concise response to the user question.
    Question: {question}
    """

    rag_prompt: str = """ 
    You are a specialist in video content creation. Your task is to develop engaging video scripts based on a user query, given a specific context that includes the user's relevance and preferences.

    Here is a list of steps that you need to follow to solve this task:

    Analyze the User Query: Examine the user-provided query: {question}.
    Analyze the Context: Assess the provided context and how the information relates to the user question: {context}.
    Generate Video Script: Create a cohesive and concise video script that aligns with the subject presented in the query and reflects the user's preferences in the context. Ensure the script includes:
    Introduction: A brief overview of the topic.
    Main Content: Key points, explanations, or demonstrations.
    Call to Action: Encouragement for viewers to engage further (e.g., like, subscribe, or visit a website).

    """

    def create_template(self, enable_rag: bool = True) -> PromptTemplate:
        if enable_rag is True:
            return PromptTemplate(
                template=self.rag_prompt, input_variables=["question", "context"]
            )

        return PromptTemplate(template=self.simple_prompt, input_variables=["question"])


class LLMEvaluationTemplate(BasePromptTemplate):
    prompt: str = """
        You are an AI assistant and your task is to evaluate the output generated by another LLM.
        You need to follow these steps:
        Step 1: Analyze the user query: {query}
        Step 2: Analyze the response: {output}
        Step 3: Evaluate the generated response based on the following criteria and provide a score from 1 to 5 along with a brief justification for each criterion:

        Evaluation:
        Relevance - [score]
        [1 sentence justification why relevance = score]
        Coherence - [score]
        [1 sentence justification why coherence = score]
        Conciseness - [score]
        [1 sentence justification why conciseness = score]
"""

    def create_template(self) -> PromptTemplate:
        return PromptTemplate(template=self.prompt, input_variables=["query", "output"])


class RAGEvaluationTemplate(BasePromptTemplate):
    prompt: str = """You are an AI assistant and your task is to evaluate the output generated by another LLM.
    The other LLM generates writing content based on a user query and a given context.
    The given context is comprised of custom data produces by a user that consists of posts, articles or code fragments.
    Here is a list of steps you need to follow in order to solve this task:
    Step 1: You need to analyze the user query : {query}
    Step 2: You need to analyze the given context: {contex}
    Step 3: You need to analyze the generated output: {output}
    Step 4: Generate the evaluation
    When doing the evaluation step you need to take the following into consideration the following:
    -The evaluation needs to have some sort of metrics.
    -The generated content needs to be evaluated based on the writing similarity form the context.
    -The generated content needs to be evaluated based on it's coherence and conciseness related to the given query and context.
    -The generated content needs to be evaluate based on how well it represents the user knowledge extracted from the context."""

    def create_template(self) -> PromptTemplate:
        return PromptTemplate(
            template=self.prompt, input_variables=["query", "context", "output"]
        )

class TextToSqlTemplate(BasePromptTemplate):
    prompt: str = """You are an SQL query generator. When a user asks a question regarding data retrieval or manipulation from a database containing 7 columns, your task is to create a precise and efficient SQL query based on their request. Consider the following:

    Understand the User's Intent: Analyze the user's question to determine what data they need.
    Identify Relevant Columns: Match the user's request with the appropriate columns in the database.
    Formulate the Query: Construct a clear SQL query that accurately reflects the user's intent, using proper syntax.
    Include Conditions: If the user specifies any conditions (e.g., filters, sorting), incorporate those into the query.
    Return the Query: Provide the generated SQL query as a response.

    ### user query: {query}
    """

    def create_template(self) -> PromptTemplate:
        return PromptTemplate(template=self.prompt, input_variables=["query"])